<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reinforcement Learning Cheat Sheet</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/3.9.1/chart.min.js"></script>
    <style>
        :root {
            --primary: #2c3e50;
            --secondary: #3498db;
            --accent: #e74c3c;
            --light: #ecf0f1;
            --dark: #34495e;
            --success: #2ecc71;
            --warning: #f39c12;
            --info: #9b59b6;
        }
        
        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: var(--primary);
            background-color: var(--light);
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        header {
            background: linear-gradient(135deg, var(--primary) 0%, var(--dark) 100%);
            color: white;
            padding: 25px;
            border-radius: 8px;
            margin-bottom: 25px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        }
        
        h1 {
            font-size: 2.2em;
            margin-bottom: 10px;
        }
        
        h2 {
            font-size: 1.8em;
            margin: 25px 0 15px;
            color: var(--secondary);
            border-bottom: 2px solid var(--secondary);
            padding-bottom: 8px;
        }
        
        h3 {
            font-size: 1.4em;
            margin: 20px 0 10px;
            color: var(--dark);
        }
        
        p {
            margin-bottom: 15px;
        }
        
        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .card {
            background: white;
            border-radius: 8px;
            padding: 20px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            transition: all 0.3s ease;
            height: 100%;
        }
        
        .card:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.15);
        }
        
        .card h3 {
            color: var(--secondary);
            margin-top: 0;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
            margin-bottom: 15px;
        }
        
        ul {
            padding-left: 20px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        .chart-container {
            background: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            margin-bottom: 30px;
        }
        
        .flow-diagram {
            background: white;
            padding: 20px;
            border-radius: 8px;
            margin: 25px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        
        .challenge {
            border-left: 4px solid var(--accent);
        }
        
        .solution {
            border-left: 4px solid var(--success);
        }
        
        .concept {
            border-left: 4px solid var(--info);
        }
        
        .tag {
            display: inline-block;
            background: var(--secondary);
            color: white;
            padding: 3px 8px;
            border-radius: 4px;
            font-size: 0.8em;
            margin-right: 5px;
            margin-bottom: 5px;
        }
        
        .tag.offline {
            background: var(--info);
        }
        
        .tag.online {
            background: var(--success);
        }
        
        .tag.llm {
            background: var(--warning);
        }
        
        .progress-bar {
            height: 30px;
            background-color: #f1f1f1;
            border-radius: 15px;
            margin: 15px 0;
            overflow: hidden;
            position: relative;
        }
        
        .progress-bar-inner {
            height: 100%;
            background: linear-gradient(90deg, var(--secondary) 0%, var(--success) 100%);
            border-radius: 15px;
            width: 75%;
            position: relative;
            animation: progress 2s ease;
        }
        
        @keyframes progress {
            from { width: 0; }
            to { width: 75%; }
        }
        
        .progress-step {
            position: absolute;
            width: 25%;
            text-align: center;
            color: white;
            font-weight: bold;
            font-size: 0.8em;
            line-height: 30px;
        }
        
        .step-1 { left: 0; }
        .step-2 { left: 25%; }
        .step-3 { left: 50%; }
        .step-4 { left: 75%; }
        
        footer {
            margin-top: 50px;
            text-align: center;
            color: var(--dark);
            font-size: 0.9em;
            padding: 20px;
            border-top: 1px solid #ddd;
        }
        
        /* Responsive adjustments */
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            
            .grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>Reinforcement Learning Cheat Sheet</h1>
        <p>A comprehensive guide to RL concepts, challenges, and integration with autoregressive methods</p>
    </header>
    
    <section>
        <h2>RL Challenges & Solutions</h2>
        <div class="grid">
            <div class="card challenge">
                <h3>Challenges With RL</h3>
                <ul>
                    <li>Long training times</li>
                    <li>Significant outcome variance between runs</li>
                    <li>Complex reward function design</li>
                    <li>Local optima traps</li>
                    <li>Struggles with complex physics & environments</li>
                    <li>Costly real-world interaction</li>
                </ul>
            </div>
            
            <div class="card solution">
                <h3>Addressing RL Challenges</h3>
                <ul>
                    <li>Unstructured environment interaction to mitigate local optima</li>
                    <li>Diversity-seeking exploration to simplify rewards</li>
                    <li>Unsupervised pre-training to build representations & initial skills</li>
                    <li>Offline RL as foundation for faster learning</li>
                    <li>Online fine-tuning for adaptation</li>
                    <li>LLM integration for better simulation</li>
                </ul>
            </div>
        </div>
    </section>
    
    <section>
        <h2>Key Concepts Visualization</h2>
        
        <div class="chart-container">
            <canvas id="entropyChart" width="400" height="200"></canvas>
        </div>
        
        <div class="grid">
            <div class="card concept">
                <h3>Entropy</h3>
                <p>Measures uncertainty in a probability distribution:</p>
                <ul>
                    <li>Broad distributions → <strong>large entropy</strong></li>
                    <li>Narrow distributions → <strong>small entropy</strong></li>
                    <li>Maximum entropy RL: maximize rewards while being as random as possible</li>
                </ul>
            </div>
            
            <div class="card concept">
                <h3>Mutual Information</h3>
                <p>Measures dependency between variables:</p>
                <ul>
                    <li>High MI → variables are highly dependent</li>
                    <li>Low MI → variables are relatively independent</li>
                    <li>MI = Entropy(X) - ConditionalEntropy(X|Y)</li>
                    <li>Used for skill diversity & meta-learning</li>
                </ul>
            </div>
            
            <div class="card concept">
                <h3>Empowerment</h3>
                <p>Measures agent's control over its environment:</p>
                <ul>
                    <li>Defined as MI between next state and current action</li>
                    <li>Higher empowerment = more control & options</li>
                    <li>Serves as intrinsic motivation</li>
                </ul>
            </div>
        </div>
    </section>
    
    <section>
        <h2>From Offline to Online RL</h2>
        
        <div class="progress-bar">
            <div class="progress-bar-inner"></div>
            <div class="progress-step step-1">Offline Data</div>
            <div class="progress-step step-2">Offline RL</div>
            <div class="progress-step step-3">Online Fine-tuning</div>
            <div class="progress-step step-4">Deployment</div>
        </div>
        
        <div class="flow-diagram">
            <canvas id="flowDiagram" width="800" height="400"></canvas>
        </div>
        
        <div class="grid">
            <div class="card">
                <h3>Offline RL as Foundation</h3>
                <div class="tags">
                    <span class="tag offline">Offline</span>
                    <span class="tag">Pre-training</span>
                </div>
                <ul>
                    <li>Leverages large datasets of past interactions</li>
                    <li>Extracts optimal decision-making strategies</li>
                    <li>Uses data to illustrate what <em>can</em> be done</li>
                    <li>Uses RL to determine what <em>should</em> be done</li>
                    <li>Addresses distributional shift with pessimism</li>
                </ul>
            </div>
            
            <div class="card">
                <h3>Online Fine-tuning</h3>
                <div class="tags">
                    <span class="tag online">Online</span>
                    <span class="tag">Adaptation</span>
                </div>
                <ul>
                    <li>Rapid adaptation to novel situations</li>
                    <li>More efficient exploration from strong priors</li>
                    <li>Combines general knowledge with optimization</li>
                    <li>Enables discovery of novel solutions</li>
                    <li>Bridges gap between offline training and deployment</li>
                </ul>
            </div>
            
            <div class="card">
                <h3>LLM Integration</h3>
                <div class="tags">
                    <span class="tag llm">LLM</span>
                    <span class="tag">Autoregressive</span>
                </div>
                <ul>
                    <li>Simulates complex environments & human behavior</li>
                    <li>Generates diverse interaction data</li>
                    <li>Enables model-based RL approaches</li>
                    <li>Frames dialogue as sequential decision-making</li>
                    <li>Token-level Q-learning for optimal responses</li>
                </ul>
            </div>
        </div>
    </section>
    
    <section>
        <h2>Advanced RL Techniques</h2>
        <div class="grid">
            <div class="card">
                <h3>Distribution Matching</h3>
                <ul>
                    <li>Reformulate RL as distribution matching on actions</li>
                    <li>Minimize KL divergence between policy's state marginal and desired state marginal</li>
                    <li>Maximum entropy objective explores options more evenly</li>
                </ul>
            </div>
            
            <div class="card">
                <h3>Unsupervised RL</h3>
                <ul>
                    <li>"Practice" by generating samples as goals</li>
                    <li>Up-weight interesting goals for more attention</li>
                    <li>Maximize MI between final state and goal</li>
                    <li>Discover diverse skills autonomously</li>
                </ul>
            </div>
            
            <div class="card">
                <h3>Meta-Learning</h3>
                <ul>
                    <li>Unsupervised meta-RL for automatic task acquisition</li>
                    <li>Propose tasks by creating rewards to maximize MI between task index and state</li>
                    <li>Different skills should visit different state-space regions</li>
                    <li>Train classifier to predict p(z|s) for skill diversity</li>
                </ul>
            </div>
            
            <div class="card">
                <h3>Robotics Applications</h3>
                <ul>
                    <li>Robotic foundation models with offline RL</li>
                    <li>Learn from diverse data including human videos</li>
                    <li>Multi-robot policies outperform task-specific ones</li>
                    <li>Use value functions to predict reachability from video</li>
                </ul>
            </div>
        </div>
    </section>
    
    <div class="chart-container">
        <canvas id="performanceChart" width="400" height="250"></canvas>
    </div>
    
    <footer>
        <p>Reinforcement Learning Cheat Sheet &copy; 2025</p>
    </footer>

    <script>
        // Render Entropy Chart
        const entropyCtx = document.getElementById('entropyChart').getContext('2d');
        const entropyChart = new Chart(entropyCtx, {
            type: 'line',
            data: {
                labels: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
                datasets: [{
                    label: 'Binary Entropy Function',
                    data: [0, 0.33, 0.5, 0.61, 0.67, 0.69, 0.67, 0.61, 0.5, 0.33, 0],
                    backgroundColor: 'rgba(52, 152, 219, 0.2)',
                    borderColor: 'rgba(52, 152, 219, 1)',
                    borderWidth: 2,
                    pointBackgroundColor: 'rgba(52, 152, 219, 1)',
                    tension: 0.4
                }]
            },
            options: {
                responsive: true,
                plugins: {
                    title: {
                        display: true,
                        text: 'Entropy Visualization (Binary Case)',
                        font: {
                            size: 16
                        }
                    },
                    legend: {
                        position: 'bottom'
                    },
                    tooltip: {
                        callbacks: {
                            label: function(context) {
                                return `Entropy: ${context.parsed.y.toFixed(2)}`;
                            }
                        }
                    }
                },
                scales: {
                    x: {
                        title: {
                            display: true,
                            text: 'Probability'
                        }
                    },
                    y: {
                        title: {
                            display: true,
                            text: 'Entropy'
                        },
                        beginAtZero: true
                    }
                }
            }
        });
        
        // Render Flow Diagram
        const flowCtx = document.getElementById('flowDiagram').getContext('2d');
        
        // Draw boxes and arrows
        function drawFlowDiagram() {
            // Clear canvas
            flowCtx.clearRect(0, 0, 800, 400);
            
            // Define colors
            const colors = {
                data: '#9b59b6',       // Purple
                offlineRL: '#3498db',  // Blue
                llm: '#f39c12',        // Orange
                onlineRL: '#2ecc71',   // Green
                deployment: '#e74c3c', // Red
                arrow: '#7f8c8d',      // Gray
                text: '#2c3e50'        // Dark blue
            };
            
            // Draw boxes
            function drawBox(x, y, width, height, text, color) {
                // Draw shadow
                flowCtx.fillStyle = 'rgba(0, 0, 0, 0.1)';
                flowCtx.fillRect(x+3, y+3, width, height);
                
                // Draw box
                flowCtx.fillStyle = color;
                flowCtx.fillRect(x, y, width, height);
                
                // Draw text
                flowCtx.fillStyle = 'white';
                flowCtx.font = '14px Arial';
                flowCtx.textAlign = 'center';
                flowCtx.textBaseline = 'middle';
                
                // Handle multi-line text
                const lines = text.split('\n');
                const lineHeight = 18;
                const textY = y + height/2 - (lines.length - 1) * lineHeight/2;
                
                lines.forEach((line, i) => {
                    flowCtx.fillText(line, x + width/2, textY + i * lineHeight);
                });
            }
            
            // Draw arrow
            function drawArrow(fromX, fromY, toX, toY, color) {
                const headLength = 10;
                const angle = Math.atan2(toY - fromY, toX - fromX);
                
                // Draw line
                flowCtx.beginPath();
                flowCtx.moveTo(fromX, fromY);
                flowCtx.lineTo(toX, toY);
                flowCtx.strokeStyle = color;
                flowCtx.lineWidth = 2;
                flowCtx.stroke();
                
                // Draw arrowhead
                flowCtx.beginPath();
                flowCtx.moveTo(toX, toY);
                flowCtx.lineTo(toX - headLength * Math.cos(angle - Math.PI/6), 
                              toY - headLength * Math.sin(angle - Math.PI/6));
                flowCtx.lineTo(toX - headLength * Math.cos(angle + Math.PI/6), 
                              toY - headLength * Math.sin(angle + Math.PI/6));
                flowCtx.closePath();
                flowCtx.fillStyle = color;
                flowCtx.fill();
            }
            
            // Draw connector label
            function drawConnectorLabel(x, y, text, color) {
                flowCtx.fillStyle = color;
                flowCtx.font = '12px Arial';
                flowCtx.textAlign = 'center';
                flowCtx.textBaseline = 'middle';
                flowCtx.fillText(text, x, y);
            }
            
            // Draw the flow diagram elements
            // Data
            drawBox(50, 100, 120, 60, 'Historical Data', colors.data);
            
            // LLM
            drawBox(50, 240, 120, 60, 'LLM\nSimulations', colors.llm);
            
            // Offline RL
            drawBox(280, 170, 120, 60, 'Offline RL', colors.offlineRL);
            
            // Online RL
            drawBox(500, 170, 120, 60, 'Online RL\nFine-tuning', colors.onlineRL);
            
            // Deployment
            drawBox(650, 170, 120, 60, 'Deployment', colors.deployment);
            
            // Arrows
            drawArrow(170, 130, 280, 170, colors.arrow); // Data to Offline RL
            drawArrow(170, 270, 280, 230, colors.arrow); // LLM to Offline RL
            drawArrow(400, 200, 500, 200, colors.arrow); // Offline RL to Online RL
            drawArrow(620, 200, 650, 200, colors.arrow); // Online RL to Deployment
            
            // Connector labels
            drawConnectorLabel(225, 140, 'Extract Strategies', colors.text);
            drawConnectorLabel(225, 250, 'Simulate Environment', colors.text);
            drawConnectorLabel(450, 180, 'Pre-trained Policy', colors.text);
            drawConnectorLabel(635, 180, 'Adapt', colors.text);
            
            // Title
            flowCtx.fillStyle = colors.text;
            flowCtx.font = 'bold 18px Arial';
            flowCtx.textAlign = 'center';
            flowCtx.fillText('RL Pipeline: From Data to Deployment', 400, 50);
        }
        
        drawFlowDiagram();
        
        // Render Performance Chart
        const perfCtx = document.getElementById('performanceChart').getContext('2d');
        const performanceChart = new Chart(perfCtx, {
            type: 'bar',
            data: {
                labels: ['Traditional RL', 'Offline RL', 'Offline+Online', 'LLM+Offline+Online'],
                datasets: [{
                    label: 'Training Time (lower is better)',
                    data: [100, 70, 50, 30],
                    backgroundColor: 'rgba(231, 76, 60, 0.7)',
                    borderColor: 'rgba(231, 76, 60, 1)',
                    borderWidth: 1
                }, {
                    label: 'Performance Score (higher is better)',
                    data: [65, 80, 90, 95],
                    backgroundColor: 'rgba(46, 204, 113, 0.7)',
                    borderColor: 'rgba(46, 204, 113, 1)',
                    borderWidth: 1
                }]
            },
            options: {
                responsive: true,
                plugins: {
                    title: {
                        display: true,
                        text: 'RL Approach Comparison',
                        font: {
                            size: 16
                        }
                    },
                    legend: {
                        position: 'bottom'
                    }
                },
                scales: {
                    y: {
                        beginAtZero: true,
                        title: {
                            display: true,
                            text: 'Relative Score'
                        }
                    }
                }
            }
        });
    </script>
</body>
</html>